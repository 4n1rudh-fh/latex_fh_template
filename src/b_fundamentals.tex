\chapter{Fundamentals}\label{chap:fundamentals}

    \section{Camera Technology}

    The \glsfirst{emva} developed a \gls{emva} 1288 Standard which helps define reliable measurement guidelines, specification parameters and characterization data that allows for easier comparison of cameras and image sensors, when choosing a suitable one for a machine vision task. This standard enables the users to evaluate the key performance parameters of digital cameras. The standard includes two categories of measurements: \emph{mandatory} and \emph{optional}. For a camera to be \gls{emva} 1288 compliant, the \emph{mandatory} measurements must be mentioned in the datasheet. Some of the important performance parameters covered by \gls{emva} 1288 include:
    \begin{itemize}
        \item Sensitivity: Ability of camera to produce signal in low-light conditions. This measures the capacity of camera to capture weak signals.
        \item \gls{dr}: Range between highest and lowest light levels that a camera can capture. Indicates camera's capacity to capture varying light conditions.
        \item \gls{snr}: Higher \gls{snr} indicates camera's capability to capture better image quality while reducing impact of noise.
        \item Temporal Dark Noise: Noise produced by the camera when there is no incident light.
        \item Temporal Readout Noise: Noise produced when reading the signal from sensor.
        \item Temporal Fixed Pattern Noise: Fixed noise that persists over multiple frames. 
        \item Pixel Non-Uniformity: This assesses the variation in sensitivity among pixels.
        \item \gls{dsnu}: This is the difference in dark signal levels among pixels.
        \item Saturation Capacity: Maximum signal level that can be handled by the pixel or whole image sensor.
        \item Linearity: This indicates the camera's response to change in incident light.
    \end{itemize}   

    \vspace{5mm}
    \nonindent The list of all parameters for the \gls{emva} 1288 parameters can be found in Table \ref{table:emva_table}.

    \section{Laser Speckle Formation}

    Most surfaces are rough on a scale of wavelength of light (with exception of mirrors), and when laser is incident on those surfaces, it is scattered in many different directions because of those surface irregularities (See Fig. \ref{fig:diffuse_reflection}) \cite{wang_2000}. If the surface with incident laser is being imaged, these waves travel in different directions and different distances to reach the image sensor. Speckles are formed on the image sensor plane, when these waves undergo constructive or destructive interference \cite{dhanasekar, goodman_book, briers}. A constructive and a destructive interference results in a bright and dark spot respectively, thus forming the \gls{lsp} as shown in Fig. \ref{subfig:laser_speckle_view_2.jpg}. A typical \gls{lsp} captured using a monochrome camera will look similar to as shown in Fig. \ref{fig:laser_speckle.png}.
    
    % For e.g. in Fig. \ref{fig:green_laser}, with paper having a higher roughness than a polished hard drive surface, it undergoes diffuse reflection when laser is incident on it.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{images/b_fundamentals/diffuse_reflection.png}
        \caption{Laser beam scattered from a rough surface. \cite{wang_2000} (Adapted from Wang et. al. 2000)}
        \label{fig:diffuse_reflection}
    \end{figure}
    
    % \begin{figure}[h]
    %     \begin{subfigure}{0.5\textwidth}
    %         \centering
    %         \includegraphics[width=0.8\textwidth]{images/b_fundamentals/white_paper.jpg}
    %         \caption{Paper}
    %         \label{subfig:white_paper.jpg}
    %     \end{subfigure}
    %     \begin{subfigure}{0.5\textwidth}
    %         \centering
    %         \includegraphics[width=0.8\textwidth]{images/b_fundamentals/green_laser.jpg}
    %         \caption{Polished hard drive surface}
    %         \label{subfig:hard_drive.jpg}
    %     \end{subfigure}
    %     \caption{Green laser hitting two different surfaces. (\textcopyright \ David Bode) \cite{img_green_laser}}
    %     \label{fig:green_laser}
    % \end{figure}

    \begin{figure}[h]
        \begin{subfigure}{0.5\textwidth}
            \centering
            \includegraphics[width=0.8\textwidth]{images/b_fundamentals/laser_pointer.jpg}
            \caption{Red laser incident on a surface.}
            \label{subfig:laser_pointer.jpg}
        \end{subfigure}
        \begin{subfigure}{0.5\textwidth}
            \centering
            \includegraphics[width=0.8\textwidth]{images/b_fundamentals/laser_speckle_view_2.jpg}
            \caption{Focussing on incident laser point.}
            \label{subfig:laser_speckle_view_2.jpg}
        \end{subfigure}
        \caption{Capturing \gls{lsp} using a camera. (\textcopyright \ Leon Gorissen) \cite{img_gorissen}}
        \label{fig:img_leon}
    \end{figure}
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{images/b_fundamentals/laser_speckle.png}
        \caption{A typical laser speckle pattern.}
        \label{fig:laser_speckle.png}
    \end{figure}

    % \section{Diffraction and Airy Disk}\label{Section:Diffraction}

    % In diffraction, light waves bend around the corners of a slit as shown in Fig. \ref{subfig:diffraction_slit}. In case of circular aperture inside a camera lens, as a result of diffraction, \emph{airy disk} can form on the image sensor (See Fig. \ref{subfig:airy_disk}). The angle $\theta$ at which the first minimum of the light wave, i.e. the first dark ring surrounding the center bright spot, occurs is given by the following formula:

    % \vspace{5mm}
    % \begin{equation}\label{eqn:objective}
    %     \sin \theta \approx 1.22 \frac{\lambda}{d}
    % \end{equation}

    % \vspace{5mm}
    % \noindent where,
    % \begin{itemize}
    %     \item $\theta$ is angle at which first minimum occurs
    %     \item $\lambda$ wavelength of incoming light
    %     \item \emph{d} is diameter of aperture
    % \end{itemize}
    
    % \vspace{5mm}
    % \noindent Hence, as \emph{d} decreases $\theta$ increases, which means the first dark ring appears farther from the center of the bright spot. Another way to frame this is, the bright spot increases in size.

    % \begin{figure}[h]
    %     \centering
    %     \includegraphics[width=0.4\textwidth]{images/b_fundamentals/diffraction_slit.png}
    %     \caption{Numerical approximation of diffraction pattern from a slit of width four wavelengths with an incident plane wave. \cite{img_diffraction_slit}}
    %     \label{subfig:diffraction_slit}
    % \end{figure}

    % \begin{figure}[h]
    %     \centering
    %     \includegraphics[width=0.4\textwidth]{images/b_fundamentals/airy_disk.jpeg}
    %     \caption{A real Airy disk created by passing a red laser beam through a \SI{90}{\micro\meter} pinhole aperture with 27 orders of diffraction. \cite{img_airy_disk}}
    %     \label{subfig:airy_disk}
    % \end{figure}


    \section{Template Matching}\label{section:template_matching}
    Template matching is a technique employed to track a template or sub-image within a larger image. By sliding the template over the image, a similarity score is calculated at each pixel location of the latter. For the purpose of template matching, correlation is often used as a criteria to measure this similarity. Pan et. al reviewed different correlation techniques used in \gls{dic} for speckle patterns and categorized them into two groups: \gls{cc} and \glsfirst{ssd} correlation criteria \cite{pan_review}. They are listed below in Table \ref{table:pan_table_cc} and \ref{table:pan_table_ssd}. The authors also stated that \glsentryshort{zncc} criterion is related to \glsentryshort{znssd} criterion, and its derivation is outlined in Ref. \cite{pan_derivation}. Similarly, the \glsentryshort{ncc} criterion can be derived from \glsentryshort{nssd} criterion as \( C_{NSSD}(p) = 2[1 - C_{NCC}(p)] \) \cite{pan_review}.

    \begin{table}[h]
        \centering
        \footnotesize
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{cc}
            \toprule
            \textbf{\gls{cc} correlation criterion} & \textbf{Definition} \\
            \midrule
            
            \glsfirst{cc}  &  \( C_{CC} = \displaystyle \sum_{i=-M}^{M} \displaystyle \sum_{j=-M}^{M} f(x_i, y_j)g(x_{i}^{'}, y_{j}^{'}) \) \\
            
            & \\
            
            \glsfirst{ncc} & \( C_{NCC} = \displaystyle \sum_{i=-M}^{M} \displaystyle \sum_{j=-M}^{M} \left[\dfrac{f(x_i, y_j)g(x_{i}^{'}, y_{j}^{'})}{\overline{f}\overline{g}}\right] \) \\
            
            & \\
            
            \glsfirst{zncc} & \( C_{ZNCC} = \displaystyle \sum_{i=-M}^{M} \displaystyle \sum_{j=-M}^{M} \left\{\dfrac{[f(x_i, y_j) - f_{m}] \times [g(x_{i}^{'}, y_{j}^{'}) - g_{m}]}{\Delta f \Delta g} \right\} \) \\
    
            \bottomrule
        \end{tabular}
        \caption{Commonly used cross-correlation criteria (Adapted from Pan et. al. 2009) \cite{pan_review}.}
        \label{table:pan_table_cc}
    \end{table}
    
    \begin{table}[h]
        \centering
        \footnotesize
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{cc}
            \toprule
            \textbf{\gls{ssd} correlation criterion} & \textbf{Definition} \\
            \midrule
            
            \glsfirst{ssd}  &  \( C_{SSD} = \displaystyle \sum_{i=-M}^{M} \displaystyle \sum_{j=-M}^{M} [f(x_i, y_j) - g(x_{i}^{'}, y_{j}^{'})]^2 \) \\
            
            & \\
            
            \glsfirst{nssd} & \( C_{NSSD} = \displaystyle \sum_{i=-M}^{M} \displaystyle \sum_{j=-M}^{M} \left[\dfrac{f(x_i, y_j)}{\overline{f}} - \dfrac{g(x_{i}^{'}, y_{j}^{'})}{\overline{g}}\right]^2 \) \\
            
            & \\
            
            \glsfirst{znssd} & \( C_{ZNSSD} = \displaystyle \sum_{i=-M}^{M} \displaystyle \sum_{j=-M}^{M} \left[\dfrac{f(x_i, y_j) - f_{m}}{\Delta f} - \dfrac{g(x_{i}^{'}, y_{j}^{'}) - g_{m}}{\Delta g}\right]^2 \) \\
    
            \bottomrule
        \end{tabular}
        \caption{Commonly used \gls{ssd} correlation criteria (Adapted from Pan et. al. 2009) \cite{pan_review}.}
        \label{table:pan_table_ssd}
    \end{table}
    
    \noindent In Tables \ref{table:pan_table_cc} and \ref{table:pan_table_ssd}:
    
    \begin{equation}
        f_{m} = \dfrac{1}{(2M + 1)^2}\sum_{i=-M}^{M}\sum_{j=-M}^{M} f(x_i, y_j)
    \end{equation}

    \begin{equation}
        g_{m} = \dfrac{1}{(2M + 1)^2}\sum_{i=-M}^{M}\sum_{j=-M}^{M} g(x_{i}^{'}, y_{j}^{'})
    \end{equation}

    \begin{equation}
        \overline{f} = \sqrt{\sum_{i=-M}^{M} \sum_{j=-M}^{M} [f(x_{i}, y_{j})]^2}
    \end{equation}

    \begin{equation}
        \overline{g} = \sqrt{\sum_{i=-M}^{M} \sum_{j=-M}^{M} [g(x_{i}^{'}, y_{j}^{'})]^2}
    \end{equation}

    \begin{equation}
        \Delta f = \sqrt{\sum_{i=-M}^{M} \sum_{j=-M}^{M} [f(x_{i}, y_{j}) - f_m]^2}
    \end{equation}

    \begin{equation}
        \Delta g = \sqrt{\sum_{i=-M}^{M} \sum_{j=-M}^{M} [g(x_{i}^{'}, y_{j}^{'}) - g_m]^2}
    \end{equation}
        
    \vspace{5mm}
    \noindent $f_m$ is the mean of $f(x_i, y_j)$ under the region of template and $g_m$ is the mean of the template. The \glsentryshort{znssd} and \glsentryshort{zncc} correlation criteria give the best noise proof performance and are insensitive to offset of lighting and change in illumination. \gls{ncc} and \glsentryshort{nssd} are insensitive to change in illumination conditions but sensitive to offset of lighting. Conversely, both \gls{cc} and \gls{ssd} are sensitive to all lighting variations \cite{lewis, pan_review}. Lewis, in his work \cite{lewis}, derives the \gls{ncc} formula, akin to the one presented by Pan et al. in their review paper \cite{pan_review}, where it is referred to as \glsentryshort{zncc}.

    \vspace{5mm}
    \noindent In Fig. \ref{fig:ncc_example}, the template (Fig. \ref{subfig:template.jpg}) is being compared with the image (Fig. \ref{subfig:card.jpg}) that contains this pattern. The process of template matching is performed by comparing each of the pixel values inside the template to the underlying image, using a technique called \emph{squared euclidean distance}. Here, the difference in pixel values for each pixel location between template and the underlying area in the image is squared and added together. The basic idea is, that if this sum has a low value, that is the probable location of template inside the image. Inside Fig. \ref{fig:corr_cmap.png}, the \gls{ncc} match is shown as the bright spot at the location where center of the template matches with the underlying image. The colorbar maps these correlation values such that darkest points inside this figure corresponds to no match and brightest point to the correlation peak.

    \begin{figure}[h]
        \begin{subfigure}{0.3\textwidth}
            \centering
            \includegraphics[width=0.8\textwidth]{images/b_fundamentals/card.jpeg}
            \caption{Image}
            \label{subfig:card.jpg}
        \end{subfigure}
        \begin{subfigure}{0.3\textwidth}
            \centering
            \includegraphics[width=0.4\textwidth]{images/b_fundamentals/template.jpg}
            \caption{Template}
            \label{subfig:template.jpg}
        \end{subfigure}
        \begin{subfigure}{0.3\textwidth}
            \centering
            \includegraphics[width=1.1\textwidth]{images/b_fundamentals/corr_cmap.jpeg}
            \caption{Peak of correlation shown as bright spot.}
            \label{fig:corr_cmap.png}
        \end{subfigure}
        \caption{Image and template used for performing \gls{ncc}. \cite{img_card}}
        \label{fig:ncc_example}
    \end{figure}

    % \begin{figure}[h]
    %     \centering
    %     \includegraphics[width=\textwidth]{images/b_fundamentals/corr_plot.png}
    %     \caption{Plot showing peak of correlation values.}
    %     \label{fig:corr_plot.png}
    % \end{figure}

    \section{\glsfirst{lsi}}\label{section:lsi}
    \gls{lsi} involves using laser source to generate \gls{lsp} and using template matching algorithms (See Section \ref{section:template_matching}) to measure change in relative position. Using \gls{lsi} on a robot involves using this laser and camera setup together as an onboard mounted sensor on robot \gls{tcp}, measuring change in relative position when robot \gls{tcp} moves relative to a surface. This is also outlined clearly in the Fig. \ref{fig:sensor_concept.png}. 
    
    \begin{figure}
        \centering
        \includegraphics[width=0.5\textwidth]{images/b_fundamentals/sensor_concept.png}
        \caption{Sensor concept. In (a) \gls{lsi} setup captures images for relative movement between robot \gls{tcp} and workpiece surface. In (b) 2D-\gls{ncc} between reference and current image gives the correlation peak indicating the occurred translation (Adapted from Charrett et. al. 2018 \cite{charrett_2018}).}
        \label{fig:sensor_concept.png}
    \end{figure}

    \clearpage