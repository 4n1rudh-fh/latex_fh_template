\chapter{State of the Art}\label{chapter:sota}
In this chapter information collected from literature survey will cover the following topics:

\begin{itemize}
    \item Experimental setup factors affecting \gls{lsp} formation
    \item Quality criteria for \gls{lsp}
    \item Speckle tracking approaches
    \item Review on template matching and feature tracking approaches for artificial speckle patterns and \gls{lsp}
    \item Image quality criteria concerning artificial speckle patterns and \gls{lsp}
    \item Real use cases of template matching
    \item Real use cases of speckle pattern quality criteria
\end{itemize}

\section{Experimental setup factors affecting \glsfirst{lsp}}

\subsection{Camera Parameters}

    \subsubsection{Exposure Time or Shutter Speed}\label{Subsubsection:Exposure_Time}
    Exposure time is defined by the amount of time the digital sensor inside the camera is exposed to light. An increase in shutter speed or decrease in exposure time means, that less light is allowed to fall on the image sensor of a digital camera.

    \vspace{5mm}
    \noindent Higher shutter speeds helps in capturing more frames in a given time. As the image sensor is exposed to light for a shorter amount of time, combined with more number of frames being captured, results in movements that appear to be frozen in images. Thus, motion blur is minimized. If for the same movement exposure time is increased, motion blur happens, as a result of which speckles would not be observed on the image sensor. Charrett et. al.  used an exposure time of \SI{200}{\micro\second} \cite{charrett_2018}. Bandari et. al. used an exposure time of \SI{600}{\micro\second}. No explanation was given by the authors for choosing these values \cite{bandari}.

    \vspace{5mm}

    \noindent Hu et. al. confirmed that speckle images captured for exposure values between \emph{B6-B10} gave speckle images of higher quality and higher contrast \noindent \cite{hu}. For their experiment defocussing degree is kept unchanged, and exposure time was adjusted from 1000-16000. A group of 16 \gls{lsp} was captured named \emph{Group B: B1-B16} (See Fig. \ref{fig:hu_fig8}). Unfortunately, no units were given for these values. Therefore, it is not possible to determine if these are actual exposure times or shutter speeds of the camera. However, it was concluded that a balance needs to be found between under- or overexposure of image sensor, as any of the extremes would result in decrease of contrast. This decrement in gray contrast of images negatively affects the algorithms used for correlation as covered in section \ref{Section:Algorithms}.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{images/c_sota/hu_fig8.png}
        \caption{\gls{lsp} captured at different exposure times. (Adapted from Hu et al. 2021) \cite{hu}}
        \label{fig:hu_fig8}
    \end{figure}

    \subsubsection{Frame Rate}\label{Subsubsection:Frame_Rate}
    \Gls{lsp} captured with higher frame rate cameras would exhibit less motion blur owing to more frames being captured in a given time. Charret et. al. and Bandari et. al. have used 500 \gls{fps} high speed camera in their setup \cite{charrett_2018} \cite{bandari}. In Ref. \cite{charrett_mars} authors mentioned that if frame rate is high, then low velocities cannot be measured as the detected translation by correlation algorithms would be less than \~0.1 pixels when using sub-pixel interpolation or 1 pixel otherwise. Therefore, appropriate frame rate should be chosen for required velocity range.

    
    \subsubsection{Aperture Size}
    Aperture is the hole that allows the incoming light to fall on image sensor. Its size controls the exposure of image sensor to light. As a result of higher shutter speeds, larger aperture is required for adequate exposure. In the literature concerning speckle patterns, aperture size has an effect on speckle size. Song et. al. captured \gls{lsp} for different aperture numbers (See Table \ref{table:song_table_c}) and named them respectively from C1 - C5. As aperture number is increasing, amount of available light falling on sensor decreases, as shown by \gls{agl} values, but \gls{ass} is increasing \cite{song}. Charrett et. al. used a 'lensless' or \emph{objective speckle setup} with no imaging lens in front of image sensor. Thus, removing the need for aperture to control speckle size \cite{charrett_2018, francis_autonomous}.
    
    \begin{table}[h]
        \centering
        \footnotesize
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{cccc}
            \toprule
            \textbf{Speckle Pattern} & \textbf{Aperture} & \textbf{\gls{ass} (Pixels)} & \textbf{\gls{agl}} \\
            \midrule
            
            C1 & 8 & 2.8 & 188.1 \\
            C2 & 11 & 3.9 & 103.8 \\
            C3 & 16 & 4.9 & 52.1 \\
            C4 & 22 & 7.4 & 25.6 \\
            C5 & 32 & 11.6 & 13.9 \\
    
            \bottomrule
        \end{tabular}
        \caption{\gls{lsp} collected for different aperture sizes (Adapted from Fig. \ref{fig:song_fig9} in Song et. al. 2020) \cite{song}.}
        \label{table:song_table_c}
    \end{table}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{images/c_sota/song_fig9.png}
        \caption{\gls{lsp} collected under different conditions: C1 - C5 for apertures (8, 11, 16, 22, 32). D1 - D5 for different laser powers (10 mW, 100 mW, 200 mW, 300 mW, 400 mW) and E1 - E5 for different temperatures (1200 °C, 1300 °C, 1400 °C, 1500 °C, 1600 °C). (Adapted from Song et. al. 2020) \cite{song}}
        \label{fig:song_fig9}
    \end{figure} 

    % \begin{figure}[h]
    %     \centering
    %     \includegraphics[width=0.7\textwidth]{images/c_sota/song_fig5.png}
    %     \caption{Speckle patterns collected at different apertures and their binary patterns: Speckle patterns A1, A2, A3, A4, A5 with the same \gls{mig} and correspond to apertures 8, 11, 16, 22, 32; Speckle patterns B1, B2, B3, B4, B5 with the same \gls{miosd} and correspond to apertures 8, 11, 16, 22, 32. \cite{song}}
    %     \label{fig:song_fig5}
    % \end{figure}

    
    \subsubsection{Resolution of Captured Image and Template/Subset Size}
    Charrett et al. used an image with a resolution of \(512 \times 512\) pixels, employing an image sensor with a pixel size of \SI{4.8}{\micro\meter} \cite{charrett_2018}. The \gls{ncc} correlation window dimensions were set at \(128 \times 128\) pixels. While a smaller correlation window allows easier \gls{ncc} computation, excessively small windows may increase the likelihood of outliers, thus compromising accuracy. In the study by Pan et al. \cite{pan_subset}, the impact of template size on displacement measurement accuracy was investigated. The authors developed an algorithm adjusting the template size based on the speckle quality parameter \glsentryshort{sssig}. For \gls{dic}, an optimal template should contain unique information to ensure reliable displacement measurements. Large templates, capturing more 'randomness,' are generally preferred, although, with sufficient image contrast, small templates can yield reliable results as well \cite{pan_subset}. Lecompte et al. \cite{lecompte} confirmed that speckle and template size influence the accuracy of displacement measurements. Large templates contribute to more accurate measurements due to increased information content. However, the paper primarily shows the influence of speckle and subset size on accuracy without describing a method for choosing a optimal speckle pattern or template size. Yaofeng et al. similarly concluded that large templates lead to more accurate results \cite{yaofeng}. But there is an upper limit to large template sizes because of lower performance due to increased computation times.

    \subsubsection{Speckle Size}\label{Subsubsection:Speckle_Size}
    The speckle size is determined by the size of the aperture hole. Particle size increases as aperture value (\emph{f-number}) increases as a result of \emph{diffraction} \cite{song}. Hu et. al. stated that optimal speckle size is between 3 - 5 pixels for better quality of \gls{lsp}. If the speckle size is too small, it leads to image under-sampling causing large interpolation bias. On the other hand, if the speckle size is too large, it leads to poor quality of images because of low detail in images, resulting in large random errors \cite{hu}. Lecompte et al. concluded that when using smaller templates, the speckle pattern with large speckles led to most inaccurate results \cite{lecompte}. Charrett et al. used a speckle size of 4 pixels for their objective speckle setup (See Section \ref{Subsubsection:Objective_Subjective}) \cite{charrett_2019}. Francis et. al. suggested a pixel square of 2 \times \ 2, so that each speckle is made of 4 pixels \cite{francis_autonomous}. For an objective and a subjective speckle setup, speckle size (\sigma) can be measured by equation \ref{eqn:objective} and equation \ref{eqn:subjective} respectively \cite{cloud}. Because of an imaging lens in subjective speckle setup, speckle size can change based on the magnification factor ($M$) and $f$-number of the lens. 
    
    \vspace{5mm}
    \begin{itemize}
        \item $\lambda$ is wavelength of laser used
        \item \emph{L} is observation distance
        \item \emph{A} is diameter of illuminated area
        \item \emph{F/a} is the \emph{f}-number of the lens
        \item \emph{M} is the magnification factor
    \end{itemize}

    \begin{equation}\label{eqn:objective}
        \textlangle \sigma_O \textrangle \ = \  \frac{\lambda L}{A}
    \end{equation}

    \begin{equation}\label{eqn:subjective}
        \textlangle \sigma_S \textrangle \ = \  \lambda \frac{F(1 + M)}{a}
    \end{equation}

    \vspace{5mm}

    \noindent Owing to use of lens and an aperture in subjective speckle setup (See Section \ref{Subsubsection:Objective_Subjective}), to increase speckle size, aperture hole size needs to be decreased (See Eqn. \ref{eqn:subjective}). Charrett et al. concluded that velocity measurement performance decreases above \SI{0.4}{\milli\meter/\second}, when increasing the speckle size over $\sim$8 pixels as seen in Fig. \ref{fig:charrett_mars_fig11}(a) \cite{charrett_mars}. The authors also concluded that, best performance in velocity measurement was extracted, when speckle size was around $\sim$2 pixels.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.7\textwidth]{images/c_sota/charrett_mars_fig11.png}
        \caption{(a) Measured velocity vs. actual velocity for different speckle sizes. (Adapted from Charrett et al. 2010 \cite{charrett_mars})}
        \label{fig:charrett_mars_fig11}
    \end{figure}

    \subsubsection{Objective vs Subjective Speckle Setup}\label{Subsubsection:Objective_Subjective}

    As shown in Fig. \ref{fig:francis_fig2}, the objective speckle setup lacks a lens in front of image sensor. According to Francis et al. and Charrett et al. it has the following advantages: decreased number of components, and removal of aperture to control speckle size \cite{charrett_2018, francis_autonomous}.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.7\textwidth]{images/c_sota/francis_fig2.png}
        \caption{Schematic of (a) Objective and (b) Subjective speckle setup (Adapted from Francis et al. 2012 \cite{francis_autonomous})}
        \label{fig:francis_fig2}
    \end{figure}

    \noindent Francis et al. used a subjective speckle setup for their experiments, where laser beam was diverged to a diameter of \SI{18}{\milli\meter} to extend beyond the \gls{fov} of imaging system. This decreased influence of gaussian beam profile of laser beam, allowing the central part of beam, where intensity is the highest, to extend beyond the imaging area. Although this allows better and consistent illumination, but it decreased the signal levels. The decreased signal levels were further compounded because of smaller aperture size being used in the setup. Hence, slower velocities were used for translation as compared to objective speckle setup \cite{francis_autonomous}.

%     \begin{table}[h]
%         \centering
%         \footnotesize
%         \renewcommand{\arraystretch}{1.2}
%         \begin{tabular}{p{3cm}p{5.5cm}p{5.5cm}}
%             \toprule
%             \textbf{Parameter} & \textbf{Objective Speckle} & \textbf{Subjective Speckle} \\
%             \midrule
%             Signal    & Dependent on configuration. & Dependent of \emph{F}-number of imaging lens. \\
%             Scaling Factor  & Dependent on configuration. & Can be determined from measurement of  \gls{fov}. \\
%             Illumination beam divergence & Relatively small to control speckle size. & Relatively large to overfill \gls{fov}. \\
%             \bottomrule
%         \end{tabular}
%         \caption{Summary of Parameters Pertinent to Choice of Speckle Type for Velocimetry Applications \cite{francis_autonomous}}
%         \label{table:francis_table1}
%     \end{table}
    
%     \begin{figure}[h]
%         \centering
%         \includegraphics[width=0.7\textwidth]{images/c_sota/francis_fig12.png}
%         \caption{The path calculated by cross-correlation of objective speckle patterns with the stages running at a maximum velocity of \SI{80}{\milli\meter/\second} (a). A pair of speckle patterns in successive frames at a point where the stages are moving at maximum velocity (b) and (c), and the normalized cross-correlation between them (d).\cite{francis_autonomous}}
%         \label{fig:francis_fig12}
%     \end{figure}

%     \begin{figure}[h]
%         \centering
%         \includegraphics[width=0.7\textwidth]{images/c_sota/francis_fig13.png}
%         \caption{The path calculated by cross-correlation of subjective speckle patterns with the stages running at a maximum velocity of \SI{50}{\milli\meter/\second} (a). A pair of speckle patterns in successive frames at a point where the stages are moving at maximum velocity (b) and (c), and the normalized cross-correlation between them (d). \cite{francis_autonomous}}
%         \label{fig:francis_fig13}
%     \end{figure}
% \clearpage

\subsection{Setup Parameters}

    \subsubsection{Distance between beam waist and detector}\label{Subsubsection:Distance_Beam_Waist_Detector}
    Charrett et. al. decided the distance between detector (D) and beam waist (S) to be 20mm as seen from Fig. \ref{fig:charrett_2018_fig2} \cite{charrett_2018}. Francis et al. \cite{francis_autonomous} defined scaling factor as ratio between speckle translation to actual translation. The authors stated that sensitivity of setup (indicated by the scaling factor) decreases as angular separation between observation and illumination direction increases. Higher scaling factor is beneficial, as it gives better speckle movement detection for actual small displacements of workpiece \cite{francis_autonomous}.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{images/c_sota/charrett_2018_fig2.png}
        \caption{(a) Schematic of sensor setup (b) 3D printed sensor mount. (Adapted from Charrett et al. 2018 \cite{charrett_2018})}
        \label{fig:charrett_2018_fig2}
    \end{figure}


    \subsubsection{Cone Angle}
    As mentioned in the section \ref{Subsubsection:Distance_Beam_Waist_Detector}, when the SRD angle (See Fig. \ref{fig:charrett_2018_fig2}) is small and the distance between beam waist and detector is small, the incidence and observation angles are closer to the normal. This results, that sensor was robust to changes in working height and small misalignments \cite{charrett_2018}. Charrett et al. also concluded from their experiments that, tilting the surface produced more error as compared to changing the vertical height distance between surface and plane containing S \& D \cite{charrett_2018}. Francis et. al. showed that, the smaller is the angular separation between the incidence angle of laser and observation angle of detector, the better is the sensitivity. Higher sensitivity is beneficial in better speckle movement detection, because a small displacement applied to sensor setup translates to larger displacement in image plane \cite{francis_autonomous}.
    
    
    \subsubsection{Height from the work surface}
    Charrett et. al. and Bandari et. al. used a setup where beam waist is \SI{150}{\milli\meter} above the working surface (See Fig. \ref{fig:charrett_2018_fig2}) \cite{charrett_2018, bandari}. No explanation was given for the specified value. In their paper, they have mentioned that change in working height resulted in positional error, as that meant that the laser spot translated by a certain value. Francis et. al. chose \SI{210}{\milli\meter} \cite{francis_autonomous}. Nagai et. al. used a setup to emit an almost parallel beam of light from the laser source \cite{nagai}. Thus, by changing heights between \SI{70}{\milli\meter} to \SI{500}{\milli\meter}, the laser spot diameter remained at an approximate value of \SI{3.7}{\milli\meter}. But, error in measurement suddenly increased after a certain value of height, owing to the weak luminance of the reflected laser as seen from Fig. \ref{fig:nagai_fig5}. Apart from this, their findings on changing height during translation of sensor setup in XY-plane, error does accumulate with either increment or decrement of height but remained within 5\% as seen from Fig. \ref{fig:nagai_fig7}.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{images/c_sota/nagai_fig5.png}
        \caption{Measurement errors for different height between sensor and surface. 2L and 1L indicate the number of laser sources. (Adapted from Nagai et al. 2010 \cite{nagai})}
        \label{fig:nagai_fig5}
    \end{figure}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{images/c_sota/nagai_fig7.png}
        \caption{Measurement error for height changes during \SI{200}{\milli\meter} movement along Y-axis. (Adapted from Nagai et al. 2010 \cite{nagai})}
        \label{fig:nagai_fig7}
    \end{figure}

    \subsubsection{Tilt/Yaw of the work surface}\label{subsubsection:tilt_yaw}
    Charrett et al. \cite{charrett_2018} explored the impact of tilt and yaw motions in their experimental investigations. Their findings highlighted that tilt in the surface induces more pronounced effects on measurement errors compared to variations in the distance between the camera-laser plane and the workpiece surface. Additionally, the study observed that the sensor's offset from the rotation center results in the measurement of additional velocities. The magnitude of these velocities depends upon both the translation amount and the rotational angle of the surface, in relation to the amount of offset from the center of rotation. Moreover, the relative movement between the sensor setup and the surface introduced spurious velocity measurements due to the surface's movement, other than in-XY-plane translations (for e.g., in-plane-rotations, out-of-plane translations, and tilts) (See Fig. \ref{fig:charrett_2018_fig4}). This led to instantaneous changes in velocity measurements occurring only during the duration of this error motion.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{images/c_sota/charrett_2018_fig4.png}
        \caption{Experimental setup used by Charrett et al. for their experiments. (Adapted from Charrett et al. 2018 \cite{charrett_2018})}
        \label{fig:charrett_2018_fig4}
    \end{figure}

    \noindent The authors also found that any yaw motion (about the Z-Axis) will result in rotation of speckle pattern and also record additional translation depending upon amount of offset from the center of rotation. It is suggested in this study to have laser spot ideally be colocated at the robot \gls{tcp} \cite{charrett_2018}. Any kind of tilt/yaw affects the efficacy of the \gls{ncc} algorithm negatively, as \gls{ncc} fails to take into account image rotation. This is further confirmed by Charrett et. al in another study \cite{charrett_extended_theory}. They tested surfaces with different gradients (See Fig. \ref{fig:charrett_extended_fig2}) and found out that, it leads to significant errors in correlation. Sjoedahl found that, with a tilt angle of less than 1/\emph{f}, with \emph{f} being the \emph{f}-number of the camera, resulted in an undetectable pattern \cite{sjoedahl}.
    
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.7\textwidth]{images/c_sota/charrett_extended_fig2.png}
        \caption{The 3D printed test objects used by Charrett et. al. in their experiments. $m$ denotes the slope of the surfaces. (Adapted from Charrett et al. 2014 \cite{charrett_extended_theory})}
        \label{fig:charrett_extended_fig2}
    \end{figure}

    \subsubsection{Monochromatic and Polychromatic Light}
    Dainty mentions that surface roughness does not affect the speckles statistics when monochromatic light was incident on the surface \cite{dainty}. But the \gls{rms} height variation $\sigma$ did affect the statistics of scattered light when polychromatic light source was used. Apart from the chromatic nature of light source, the coherence of the light also had an effect on the statistical properties of speckle pattern.

    \subsubsection{Velocity}
    Nagai et. al concluded that measurement error increased with increasing speed and acceleration values. But the maximum error was less than 3\% for a velocity of 400 mm/s (See Fig. \ref{fig:nagai_fig8}) \cite{nagai}. Charrett et. al. found out that blurring of speckles at high velocities produced positional errors \cite{charrett_2018}. In another study by Charrett et al. \cite{charrett_mars}, low velocities are not measured if the camera's frame rate is high, as the speckle shift detected by correlation algorithms would be less than \~0.1 pixels when using sub-pixel interpolation or 1 pixel otherwise. Smid et. al. were unable to record the difference between speckle displacement of 1-3 pixels using \gls{ncc} between frames due to the low velocity values. Minimal speckle displacement recommended by the authors is 4 pixels \cite{smid_2007}.
    
    \subsubsection{Decorrelation}\label{subsubsection:decorrelation}
    Briers et. al. mentioned, that when there are small movements to the surface being imaged, the speckles remain correlated. But for larger translations, the speckle patterns \emph{decorrelate} and change completely \cite{briers}. Therefore, \gls{lsp} are sensitive to change in position, yaw, tilt, height. Hu et. al. also stated large displacements or tilts should be avoided, as decorrelation would affect the correlation calculation negatively \cite{hu}. Charrett et. al. have also mentioned that translation and decorrelation of speckle patterns dependent on object's rotation, translation, strain and surface roughness \cite{charrett_2018}. Sjoedahl et. al. made it sure that orientation of surface does not change, as it would result in complete decorrelation, and metal components could not be verified with their \emph{laser speckle fingerprints} \cite{sjoedahl}. \Gls{lsp} can deviate also, because of fluctuations in sampling of \Gls{lsp}, random camera noise and power fluctuations in laser source \cite{charrett_2019}. These are also the reasons, why a database approach would be discouraged going forward with the thesis.

    % \begin{figure}[h]
    %     \centering
    %     \includegraphics[width=0.5\textwidth]{images/c_sota/nagai_fig10.png}
    %     \caption{Result of sensor output for surface moving at very high speed with sensor placed on plastic plate rotated by turntable. (\cite{nagai})}
    %     \label{fig:nagai_fig10}
    % \end{figure}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{images/c_sota/nagai_fig8.png}
        \caption{Error at different velocities. (Adapted from Nagai et. al 2010 \cite{nagai})}
        \label{fig:nagai_fig8}
    \end{figure}
    

    \subsubsection{Laser Power}
    Song et al. collected \glspl{lsp} for different laser powers in Table \ref{table:song_table_d}, and named the corresponding \glspl{lsp} D1-D5 respectively \cite{song}. The laser power affects brightness and contrast of \gls{lsp} as can seen from the \gls{agl} values.

    \begin{table}
        \centering
        \footnotesize
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{cccc}
            \toprule
            \textbf{Speckle Pattern} & \textbf{Laser Power (mW)} & \textbf{\gls{ass} (Pixels)} & \textbf{\gls{agl}} \\
            \midrule
            
            D1 & 10 & 4.0 & 10.4 \\
            D2 & 100 & 3.8 & 83.7 \\
            D3 & 200 & 3.7 & 151.4 \\
            D4 & 300 & 2.9 & 193.4 \\
            D5 & 400 & 1.4 & 222.4 \\
    
            \bottomrule
        \end{tabular}
        \caption{Summary of \gls{lsp} collected for different laser power (Adapted from \ref{fig:song_fig9} in Song et al. 2020 \cite{song}).}
        \label{table:song_table_d}
    \end{table}


    \subsubsection{Temperature}
    Song et al. also sampled \gls{lsp} for different temperatures as shown in Table \ref{table:song_table_e} and showed that background radiation in high temperature affects brightness and contrast of speckle pattern, but it does not affect size and shape of speckle particles \cite{song}. This can be observed from the \gls{agl} and \gls{ass} values respectively.

    \begin{table}
        \centering
        \footnotesize
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{cccc}
            \toprule
            \textbf{Speckle Pattern} & \textbf{Temperature (°C)} & \textbf{\gls{ass} (Pixels)} & \textbf{\gls{agl}} \\
            \midrule
            
            E1 & 1200 & 6.8 & 64.3 \\
            E2 & 1300 & 6.7 & 70.8 \\
            E3 & 1400 & 7.0 & 89.5 \\
            E4 & 1500 & 7.3 & 116.7 \\
            E5 & 1600 & 8.6 & 181.1 \\
    
            \bottomrule
        \end{tabular}
        \caption{\gls{lsp} collected under different temperatures (Adapted from Fig. \ref{fig:song_fig9} in Song et al. 2020 \cite{song}).}
        \label{table:song_table_e}
    \end{table}
    
\vspace{5mm}
\subsection{Material Parameters}

    \subsubsection{Surface Roughness}
    Dainty in his article has mentioned that, if a surface has a roughness greater than wavelength of incident light, a speckle pattern will be produced, when a monochromatic laser is incident on it \cite{dainty}. Briers et al. state size of individual speckles is entirely dependent on the wavelength of the incident light and size of the aperture hole used to image the pattern \cite{briers}. An experimental verification by Hu et al. confirmed the fact that surface roughness had little impact on quality of speckle images \cite{hu}. Song et al. stated that the smaller the value of roughness is, better is the contrast. But it does not affect the size of speckle particles \cite{song}.
    

    \subsubsection{Surface Material}
    Song et al. collected \glspl{lsp} for different materials at different aperture \emph{f-numbers} (See Table \ref{table:song_table_g}) \cite{song}. The captured \glspl{lsp} corresponded to G1-G5 respectively (See Fig. \ref{fig:song_fig15}). For an aperture size, ceramic has higher \gls{agl} values as compared to stainless steel and carbon-composite. With increasing \emph{f}-number, the \gls{agl} values decrease because of less available light falling on sensor for all materials. Another effect of decreasing aperture hole size is, that \gls{ass} is increasing for all materials.
    \begin{table}[h]
        \centering
        \begin{subtable}{\textwidth}
            \centering
            \footnotesize
            \begin{tabular}{cccccccc}
                \toprule
                \textbf{Speckle Pattern} & \textbf{Aperture ($f$-number)} & \multicolumn{3}{c}{\textbf{\gls{agl}}} \\
                &  & \multicolumn{1}{c}{\textbf{Ceramic}} & \multicolumn{1}{c}{\textbf{Stainless Steel}} & \multicolumn{1}{c}{\textbf{Carbon Composite}} \\
                \midrule
                G1 & 8 & 203.2 & 137.5 & 23.7 \\
                G2 & 11 & 116.7 & 75.2 & 13.7 \\
                G3 & 16 & 60.0 & 38.0 & 8.4 \\
                G4 & 22 & 30 & 21.1 & 5.9 \\
                G5 & 32 & 16 & 11.3 & 4.7 \\
                \bottomrule
            \end{tabular}
        \caption{\gls{agl} values for different apertures and corresponding materials.}
        \end{subtable}
        
        \vspace{3mm}

        \begin{subtable}{\textwidth}
            \centering
            \footnotesize
            \begin{tabular}{cccccccc}
                \toprule
                \textbf{Speckle Pattern} & \textbf{Aperture ($f$-number)} & \multicolumn{3}{c}{\textbf{\gls{ass}}} \\
                &  & \multicolumn{1}{c}{\textbf{Ceramic}} & \multicolumn{1}{c}{\textbf{Stainless Steel}} & \multicolumn{1}{c}{\textbf{Carbon Composite}} \\
                \midrule
                G1 & 8 & 3.0 & 3.6 & 3.6 \\
                G2 & 11 & 4.7 & 3.5 & 3.5 \\
                G3 & 16 & 5.3 & 4.5 & 4.5 \\
                G4 & 22 & 7.5 & 6.6 & 6.6 \\
                G5 & 32 & 12.6 & 8.9 & 8.9 \\
                \bottomrule
            \end{tabular}
        \caption{\gls{ass} values for different apertures and corresponding materials.}
        \end{subtable}

        \caption{Summary of \glspl{lsp} collected for different apertures and materials. (Adapted from Fig. \ref{fig:song_fig15} in Song et al. 2020 \cite{song})}
        \label{table:song_table_g}
    \end{table}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.65\textwidth]{images/c_sota/song_fig15.png}
        \caption{Materials used and corresponding \glspl{lsp} (a) Different materials (b) \gls{lsp} of different material specimens for diofferent aperture sizes: G1, G2, G3, G4, G5 correspond to apertures 8, 11, 16, 22, 32. (Adapted from Song et al. 2020 \cite{song})}
        \label{fig:song_fig15}
    \end{figure}

    \clearpage

    \vspace{5mm}
    \noindent Nagai et. al. tested their setup to understand how different materials, for e.g. artificial lawn, stone, carpet, sand etc. as shown Fig. \ref{fig:nagai_fig12}, affected the tracking performance of \gls{lsp}. Materials such as paper, stone, plastic and aluminum plates are used, and absolute error recorded was less than \SI{8}{\milli\meter} (4\% of \SI{200}{\milli\meter}). The error recorded for artificial lawn was greater than \SI{10}{\milli\meter} (5\% of \SI{200}{\milli\meter}) (See Fig. \ref{fig:nagai_fig11}) \cite{nagai}.


    \begin{figure}[h]
        \centering
        \includegraphics[width=0.45\textwidth]{images/c_sota/nagai_fig12.png}
        \caption{Various materials used in experiment by Nagai et al. (Adapted from Nagai et al. 2010 \cite{nagai})}
        \label{fig:nagai_fig12}
    \end{figure}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{images/c_sota/nagai_fig11.png}
        \caption{Measurement error for \SI{200}{\milli\meter} displacement on different surface materials. 2L and 1L denotes the number of laser sources used. (Adapted from Nagai et al. 2010 \cite{nagai})}
        \label{fig:nagai_fig11}
    \end{figure}

    
\section{Quality criteria for speckle patterns}

Referring to the findings illustrated in Fig. \ref{fig:insert_fig}, the evaluation of speckle pattern quality is determined with an objective to discern the quality criteria applicable to \gls{lsp}. While the emphasis is on identifying criteria specific to \gls{lsp}, the literature survey also incorporates considerations of quality criteria applicable to artificial speckle patterns.

    \subsection{Global Criteria}
    
    \subsubsection{\glsfirst{mig}}\label{subsubsection:mig}

        Pan et al. introduced a global speckle quality parameter called \gls{mig} ($\delta_f$) in their study \cite{pan_mig}. The authors found that \gls{mig} has direct effect on mean bias error and standard deviation of error for measured displacements. The use of global quality parameter is justified by authors, because speckles inside an image are normally distributed. Therefore, the local parameters for different subsets have minimal differences.

        \begin{equation}
            \delta_f = \dfrac{\displaystyle \sum_{i=1}^{W} \displaystyle \sum_{j=1}^{H} |\nabla f(x_{ij})|}{(W \times H)}
        \end{equation}

        \noindent where,
        \begin{itemize}
            \item \(|\nabla f(x_{ij})| = \sqrt{f_x(x_{ij})^2 + f_y(x_{ij})^2}\) is the modulus of local intensity gradient
            \item \( f_x(x_{ij}), f_y(x_{ij}) \) are first derivatives of intensity along X- and Y-axis respectively at a pixel point $x_{ij}$
            \item $W$ and $H$ are the image width and height.
        \end{itemize}
    
    \subsubsection{\glsfirst{miosd}}
        Yu et al. described another speckle quality parameter called \gls{miosd} ($\omega_f$), and found that, measurement accuracy is dependent on both \gls{mig} and \gls{miosd}. According to the authors, high quality speckle patterns should have large \gls{mig} and lower \gls{miosd}. This quality parameter reflects the smoothness of gray surface of speckle patterns. Motivation of the authors behind needing this parameter is, that even speckle patterns with same \gls{mig} ($\delta_f$) can have different accuracies for measured displacements \cite{yu_miosd}. 

        \begin{equation}
            \omega_f = \dfrac{\displaystyle \sum_{i=1}^{W} \displaystyle \sum_{j=1}^{H} |\nabla^2 f(x_{ij})|}{(W \times H)} 
        \end{equation}

        \noindent where,
        \begin{itemize}
            \item \(|\nabla^2f(x_{ij})| = \sqrt{f_{xx}(x_{ij})^2 + f_{yy}(x_{ij})^2}\) is modulus of second derivative of local intensity and,
            \item $f_{xx}(x_{ij})$ and $f_{yy}(x_{ij})$ are second derivatives of intensities in X- and Y-directions of a pixel $x_{ij}$. 
        \end{itemize}

        \noindent The second derivatives can be calculated as follows:

        \begin{equation}
            f_{xx}(x_{ij}) = f(i,j-1) - 2f(i,j) +f(i,j+1)
        \end{equation}

        \begin{equation}
            f_{yy}(x_{ij}) = f(i-1,j) - 2f(i,j) + f(i+1,j)
        \end{equation}

        \noindent As per the findings from experiments conducted by authors, the so called 'good' speckle pattern should have large \gls{mig} and small \gls{miosd}. If the speckle was smaller than 2 pixels, then the speckle pattern produced larger deviation in measured displacement, which correlated to a higher \gls{miosd} value. On the other hand, if speckle size was greater than 5 pixels, image had a small \gls{mig} and less spatial features for accurate displacement measurement \cite{yu_miosd}.

    \subsubsection{\gls{msf}}
        
        Hua et al. developed another speckle quality criteria called \gls{msf} ($S_f$). Firstly a subset of 1 point and 8 neighboring points are selected (See Fig. \ref{fig:msf_subset.png}). Then, from this subset a local parameter $(S_p)$ is calculated using the Eqn. \ref{eqn:local_msf}. It compares the pixel gray value of each point with the mean gray value of the subset, thus capturing local subset fluctuations in gray level. The global \gls{msf} parameter is calculated by taking ($S_p$) for the different points inside the image and using the Eqn. \ref{eqn:global_msf}. The authors applied numerical translations on the speckle patterns and observed that mean bias error in measured displacements is small when $S_f$ is high \cite{hua_msf}.

        \begin{figure}[h]
            \centering
            \includegraphics[width=0.35\textwidth]{images/c_sota/msf_subset.png}
            \caption{Selecting points inside a subset. (Adapted from Hua et al. 2011 \cite{hua_msf})}
            \label{fig:msf_subset.png}
        \end{figure}        
        
        \begin{equation}
            S_p = \sum_{i=1}^{3} \sum_{j=1}^{3} |a_{ij} - \overline{a}|
            \label{eqn:local_msf}
        \end{equation}

        \begin{equation}
            S_f = \dfrac{\sum_{p \in F} S_p}{H \times V}
            \label{eqn:global_msf}
        \end{equation}
    
    \subsubsection{\gls{se}}
        Liu et al. developed a quality parameter based on concept of entropy. This criterion quantifies information content of an image and captures `randomness' inside a speckle pattern.

        \begin{equation}
            H(Y) = - \displaystyle \sum_{j=0}^{2^{\beta} - 1} p(a_j)\ log(p(a_j)) 
        \end{equation}

        where,
        \begin{itemize}
            \item H represents Shannon entropy (bits/pixel), 
            \item $\beta$ denotes pixel depth of the image,
            \item $p(a_j)$ signifies normalized probability of occurrence of each gray level. 
        \end{itemize}

        \noindent In order to verify the accuracy of measured displacements using \gls{dic}, the images were numerically deformed to avoid errors introduced by imaging system. The experimental findings showed that images with large \gls{se} had small mean bias error. High \gls{se} values denotes that speckle image has more feature information or higher speckle `uniqueness' \cite{liu_shannon}.

    \subsubsection{\glsfirst{sdgis}}
        To take aspects of gray intensities and speckle morphology (i.e speckle size and density) into account, Park et al. developed a global quality criterion. Artificial speckle patterns were generated for the study using airbrush techniques. The motivation of the authors behind using ths parameter is that, using gray-intensity alone to judge the speckle pattern quality does not take into account the variability of speckles within the image. 
        
        \vspace{5mm}
        \noindent Quantifying quality of a speckle pattern involves, firstly, identifying boundary of speckles by converting a speckle pattern image to a binary image using Otsu's method of thresholding \cite{otsu}. \gls{SDGIS} calculation is then made for each speckle. As this is still local assessment of quality for one speckle, the general quality assessment is done for the subset region. Distribution curves of \gls{sdgis} are generated for each subset, and then averaged over a given percentage for overall quality assessment. More details can be found in their paper \cite{park_sdgis}.

        \begin{equation}
            \rho = SD_{R50} \dfrac{SD_{R75} - SD_{R25}}{0.5}
        \end{equation}

        \noindent where,
        \begin{itemize}
            \item $\rho$ is speckle pattern quality,
            \item $SD_{R25}$, $SD_{R50}$, $SD_{R75}$ are lower quartile (25\%), median (50\%) and upper quartile (75\%) in cumulative distribution curve of \gls{sdgis}.
        \end{itemize}

        \noindent Higher \gls{sdgis} means higher level of gray-gradient and can hence provide more `uniqueness' in image correlation. The authors observed that, when distribution curves of \gls{sdgis} are wide and value of $\rho$ is large, errors in \gls{dic} measurement are low \cite{park_sdgis}. 

    \subsubsection{E_f}
    According to Hu et al. \cite{hu_ef}, most of the existing literature on speckle pattern quality uses only one parameter to evaluate mean bias error and standard deviation of error. On the contrary, the principle of both these error models are quite different from each other. In their study, the authors used \gls{mig} to judge speckle pattern quality based on standard deviation of error. Additionally, $E_f$ is derived based on intensity gradient and its second derivative based on mean bias error. $E_f$ was also compared with different image quality criteria by using 8 artificial speckle patterns. The translation movement was applied on speckle patterns numerically using the fourier shifting method. 

    \vspace{5mm}
    \noindent The bias error calculation $k_x$, $k_y$ was done for both X- and Y-directions for whole speckle pattern using the Eqn. \ref{eqn:ef_kx} and \ref{eqn:ef_ky}. It can be seen from these equations that $E_f$ is related to first and second order image intensity gradient. 
    
    \begin{equation}
        k_x = \dfrac{ \sum_{i=1}^{W} \sum_{j=1}^{H} |\nabla^2 f_x (x_{ij}) \ \nabla f_x (x_{ij}) | }{ \sum_{i=1}^{W} \sum_{j=1}^{H} [\nabla f_x (x_{ij})]^2 }
        \label{eqn:ef_kx}
    \end{equation}
    
    \begin{equation}
        k_y = \dfrac{ \sum_{i=1}^{W} \sum_{j=1}^{H} |\nabla^2 f_y (x_{ij}) \ \nabla f_y (x_{ij}) | }{ \sum_{i=1}^{W} \sum_{j=1}^{H} [\nabla f_y (x_{ij})]^2 }
        \label{eqn:ef_ky}
    \end{equation}

    \begin{equation}
        E_f = \sqrt{k{_x}^{2} + k{_y}^{2}}
    \end{equation}

    \noindent In conclusion, the authors found that order of quality of speckle patterns can differ from one criteria to another because of different definitions of quality and different care indexes. With regards to \gls{mig} and $E_f$, the order of speckle pattern quality are aligns with experimental findings. Additionally the authors observed, that in relation to mean bias error and standard deviation of error, $E_f$ and \gls{mig} are more efficient in assessing the speckle pattern quality as compared to other image quality parameters like \gls{se} and \gls{mffi} \cite{hu_ef}.

    \subsection{Local Criteria}

    \subsubsection{\glsfirst{sssig}}\label{subsubsection:sssig}
    Pan et al. investigated the effect of subset size on measurement accuracy in the Ref. \cite{pan_subset}.  To define a subset, if an image is divided into $n$ equal sub-images, then each of these sub-images can be called as a subset. In their study they derive a theoretical model that is based on correlation criteria \gls{ssd} (See Section \ref{section:template_matching}) that can accurately predict accuracy of displacement measurement based on the value of \glsentryshort{sssig}.

    \vspace{5mm}
    \noindent In conclusion, the authors found that displacement measurement accuracy can be improved by the following:
    \begin{itemize}
        \item Increasing the subset \glsentryshort{sssig}.
        \item Using a high bit depth camera (12-bit or 16-bit).
        \item Increasing the contrast of image. The authors did not provide any specifics here.
        \item Decreasing the image noise by using cooled \gls{ccd} and high quality camera lens.
    \end{itemize}


    \begin{equation}
        \glsentryshort{sssig} = \displaystyle \sum_{i=1}^N \displaystyle \sum_{j=1}^N [f_{x,y(x_{ij})}]^2
    \end{equation}
    
    \subsubsection{Subset Entropy}

    Yaofeng et al. in their study introduced a local quality parameter known as \emph{subset entropy} (\delta) \cite{yaofeng}. Here, the subset is defined as 8 neighboring pixels around the pixel of interest. The motivation for this study by the authors is to define this local parameter that can evaluate the effect of this image quality of each subset on accuracy of measured displacement.

    \begin{equation}
        \delta = \dfrac{\sum_{P \in S} \sum_{i=1}^{8}|I_P - I_i|}{2^\beta MN}
    \end{equation}

    where,
    \begin{itemize} 
        \item $\delta$ denotes subset entropy
        \item $P$ is a pixel point inside subset $S$
        \item Subset $S$ dimensions are $M\times N$
        \item $I_P$ is intensity at point $P$
        \item $I_i$ is intensity at one of the 8 pixel points neighboring point $P$
        \item \beta\ is the pixel depth
    \end{itemize}

    \noindent The experiment findings by Yaofeng et al. show that subset entropy can quantify subset image quality and have direct effect of correlation accuracy. The standard deviation of measured displacement decreases with larger subset entropy \cite{yaofeng}.

    \subsubsection{\glsfirst{ass}}
    Lecompte et al. investigated effects of subset size and speckle size on accuracy of measured displacements, using image morphology method to calculate speckle size. By repeated erosion and dilation procedures, thresholding method is used to identify a speckle. The authors concluded from the conducted experiments that, larger subsets with larger speckle sizes yielded optimal results. However, this paper only demonstrated that there is dependence of speckle size and subset size on displacement measurement, but does not provide any method to obtain optimal speckle size or subset size \cite{lecompte}.  

    \vspace{5mm} better present equations you introduce directly after mentioning them in the text. that way it is better to understand. It is the same with images

    \vspace{5mm} Hu et al. in their findings conclude that resolution and accuracy of correlation methods used with \gls{lsp} are dependent on defocussing degree, which affects the speckle particle size and depends on the focal length and speckle pattern quality \cite{hu}. According to Charrett et. al., using image filters such as binary threshold and Prewitt kernels (See Fig. \ref{fig:charrett_mars_fig12}) lead to reliable velocity measurements \cite{charrett_mars}. In their experiment \emph{Q-value} of 1.1, means the velocity measurement using \gls{ncc} could be trusted. The calculated velocities plotted against stage velocities were plotted for each of the filters as shown in Fig. \ref{fig:charrett_mars_fig13} (a). As the \emph{Q-value} drops below the threshold of 1.1, the image filter used in velocity measurement becomes unreliable. For e.g. Canny filter can measure velocities to a good approximation when velocities are around \SI{0.7}{\milli\meter/\second}. Fig. \ref{fig:charrett_mars_fig13} (b) plot shows \emph{Q-values} against stage velocities. \emph{Q-values} for Prewitt filter are also greater than \gls{lsp} with no filter. 


    \begin{figure}[h] 
        \centering
        \includegraphics[width=0.6\textwidth]{images/c_sota/charrett_mars_fig12.png}
        \caption{Typical speckle images: (a) no pre-filter, (b) Canny edge detection, (c) binary threshold, (d) Prewitt gradient filters. \cite{charrett_mars}}
        \label{fig:charrett_mars_fig12}
    \end{figure}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.7\textwidth]{images/c_sota/charrett_mars_fig13.png}
        \caption{(a) The mean calculated v component of velocity and (b) the minimum correlation Q-value that occurred plotted against stage velocity using the \gls{ncc} method and different pre-filters. \cite{charrett_mars}}
        \label{fig:charrett_mars_fig13}
    \end{figure}

    \subsection{Miscellaneous}

    \subsubsection{\glsfirst{mffi}}
        

\section{Speckle tracking approaches}\label{Section:Algorithms}

As per the literature survey, two image processing techniques have been widely used, namely \Gls{ncc} and using feature tracking using OpenCV \cite{opencv}. Song et. al. noted that accuracy of \gls{dic} depends on a lot of factors, for e.g. quality of speckle pattern, shape function, correlation function, sub-pixel algorithm \cite{song}. Lewis outlined the techniques of \gls{ncc} for purpose of feature tracking \cite{lewis}. The author also concluded that relative performance of \gls{ncc} depends on search window size or to ratio of feature size to search window size. Charrett et. al. used 2D-\gls{ncc} + 3 - Point Gaussian Fit for their experiment \cite{charrett_2018}. Here, the difference of position between center of the reference image and the location of peak of \gls{ncc} denotes the relative movement of robot \gls{tcp} with respect to surface (See Fig. \ref{fig:charrett_2018_fig1}).  

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{images/c_sota/charrett_2018_fig1.png}
    \caption{In (a) the sensor is attached to the robot end-effector to measure relative in-plane translation between the robot and workpiece. In (b) the signal processing principle is shown with the 2D cross-correlation between a reference and new speckle pattern computed with the peak giving the translation of the pattern (Ax, Ay). \cite{charrett_2018}}
    \label{fig:charrett_2018_fig1}
\end{figure} 

\noindent Charrett et. al. found out that accuracy of feature tracking approach using OpenCV is similar to the NCC + Gaussian Peak interpolation approach \cite{charrett_2019}. Still all methods exhibit pixel locking effects \cite{raffel}. Advantage of feature tracking in OpenCV is that, it can measure rotation upto a certain range depending on the type of method used, which \gls{ncc} cannot. Not only that, as per their results, accuracy of translation measurements from these OpenCV features is similar to \gls{ncc} or in some cases even better (See Fig. \ref{fig:charrett_2019_fig2}). Another advantage of this approach is, if the feature tracking methods are optimized enough, they can perform faster and more robust detections \cite{charrett_2019}.

\vspace{5mm}
\noindent So far, no algorithms has been found that measures pure rotation. But, that is out of the scope of this thesis and hence will not be tested. \cite{charrett_mars} also compared \gls{ncc} with Radon Transformation and Optical Flow algorithms and concluded them unsuitable for the application of velocity measurement. Radon transformation was deemed unsuitable because it is computationally expensive and Optical Flow approach required calibration for each type of surface to be able to perform velocity measurement. They found that \gls{ncc} was best suited approach with odometry error \~{}0.2\% at speeds of \SI{0.1}{\milli\meter/\second} and 0.75\% at \SI{50}{\milli\meter/\second}. In the methodology used for velocity measurements by Charrett et. al. \cite{charrett_wpos}, because of peak locking \cite{raffel}, Gaussian 3-point interpolation is required to have sub-pixel accuracy to measure translation. Still with each re-referencing procedure used in their methodology, a positional error will accumulate. This can make a difference in the end, if the application is for long-range translation measurement or short range, vibration measurement.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/c_sota/charrett_2019_fig2.png}
    \caption{Comparison between experimental speckle velocimetry data processed using the normalized cross-correlation (\gls{ncc}) and feature tracking methods. The speckle shift found using the \gls{ncc} method is shown by the solid and dashed lines for the x and y components, respectively. The feature tracking results are shown as the data points, crosses, and dots for the x and y components, respectively. \cite{charrett_2019}}
    \label{fig:charrett_2019_fig2}
\end{figure} 

% \section{Summary}\label{section:summary}
% There are a total of 17 factors that can influence the \gls{lsp} and the \gls{dic} techniques as per the literature review. They are as follows:

% \begin{itemize}
%     \item Exposure Time
%     \item Aperture Size
%     \item Frame Rate of Camera
%     \item Laser wavelength
%     \item Correlation Window Size
%     \item Image Resolution of Camera
%     \item Speckle Size
%     \item Objective vs. Subjective Speckle Setup
%     \item Height of Surface from Sensor Setup
%     \item Tilt or yaw for the surface material
%     \item Distance between laser source and detector
%     \item Velocity of surface movement
%     \item Laser Power
%     \item Temperature
%     \item Roughness
%     \item Material Parameters
%     \item Image Filters in \cite{opencv}
% \end{itemize}

% Methodology:

% \begin{itemize}
%     \item How do different materials affects speckle size and speckle pattern in general?
%     \item charrett2018 500fps, 200us exposure time, 512x512 pixels
%     \item Exposure time? Affected by aperture size and shutter speed. How do these factors affect speckle pattern?
%     \item charrett2018 detector and focus point in same plane and 150mm above the surface
%     \item charrett2018 balanced angle geometry: distance between detector and focus point is 50mm, zero sensitivity to out of plane motion
%     \item charrett2018 effect of the SDR angle on sensitivity
%     \item charrett2018 Objective setup. No lens in front of imaging camera. Therefore small aperture not needed to increase speckle size. So in such a case how does one increase speckle size?
%     \item balance high frame rate with short exposure time. But then increase the camera aperture hole at risk of decreasing pixel size. The short exposure time can be countered with increasing the laser power, working with higher reflectivity material, decreasing the distance between detector and surface, and improving sensitivity of detector \cite{charret_autonomous}
%     \item Therefore the setup needs to be recreatable. Because sensitive to yaw, tilt etc.
% \end{itemize}

\clearpage